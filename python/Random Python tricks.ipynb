{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aim : to gather knowledge and custom functions discovered over the time on web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define a function to calculate quartiles for a use in population and assign a score\n",
    "credit to https://towardsdatascience.com/find-your-best-customers-with-customer-segmentation-in-python-61d602f9eee6\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T09:20:35.080390Z",
     "start_time": "2019-02-13T09:20:35.075020Z"
    }
   },
   "outputs": [],
   "source": [
    "#define a function that will be used to assign the quartiles to the users\n",
    "def Qscore(x,p,d):\n",
    "    if x <= d[p][0.25]:\n",
    "        return 1\n",
    "    elif x <= d[p][0.50]:\n",
    "        return 2\n",
    "    elif x <= d[p][0.75]: \n",
    "        return 3\n",
    "    else:\n",
    "        return 4\n",
    "    \n",
    "#usage\n",
    "df['categorical_variable'] = df['categorical_variable'].apply(Qscore, args=('categorical_variable',quantiles))\n",
    "\n",
    "#to calculate the quartile based on the values that is in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More on segmentation\n",
    "1. How to create a weighted percentile: http://yiqun-dai.blogspot.com/2017/03/weighted-percentile-in-python-pandas.html\n",
    "2. Customer segmentation in Python: http://blog.yhat.com/posts/customer-segmentation-using-python.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split a datasert for training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T09:29:11.678219Z",
     "start_time": "2019-02-13T09:29:10.849999Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#need to split the dataframes into 2 sets - testing and training one\n",
    "# (c) Credit to :  Aurélien Géron, \"Hands-On Machine Learning with Scikit-Learn & TensorFlow\"\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    "    shuffled_indices=np.random.permutation(len(data))\n",
    "    test_set_size=int(len(data) * test_ratio)\n",
    "    test_indices=shuffled_indices[:test_set_size]\n",
    "    train_indices=shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "train_set, test_set = split_train_test(model, 0.2)\n",
    "print(len(train_set), \"train +\", len(test_set), \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Apply K-means to  write back the clusters based on similarity\n",
    "\n",
    "Credit to : http://blog.yhat.com/posts/customer-segmentation-using-python.html\n",
    "\n",
    "More on K-means: https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "cluster = KMeans(n_clusters=4)\n",
    "df_r['cluster'] = cluster.fit_predict(df_r[df_r.columns[3:5]])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
